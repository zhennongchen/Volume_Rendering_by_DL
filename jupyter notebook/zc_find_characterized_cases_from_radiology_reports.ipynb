{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this script take key words as the input and return the cases that contain this input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(string):\n",
    "    # replace symbols\n",
    "    output = string.replace(',',' , ').replace(':',' : ').replace('-',\" - \")\\\n",
    "    .replace(';',' ; ').replace('?',' ? ').replace('. ',' . ').replace('  ',' ')\n",
    "    # replace the white space in the start\n",
    "    position = 0\n",
    "    output = list(output)\n",
    "    while True:\n",
    "        if output[position] == ' ':\n",
    "            output[position] = ''\n",
    "            position += 1\n",
    "        else:\n",
    "            break\n",
    "    output = \"\".join(output)\n",
    "    return output\n",
    "\n",
    "def indexes_for_duplicates_in_list(lst, item,lower = True):\n",
    "    # in case the length of item > 1, combine every N element in the list together, N = len of item \n",
    "    len_item = len(item.split())\n",
    "    new_lst = []\n",
    "    for i in range(0,len(lst)-(len_item-1)):\n",
    "        element = []\n",
    "        for ii in range(0,len_item):\n",
    "            element.append(lst[i + ii])\n",
    "        new_lst.append(element)\n",
    "\n",
    "    indexes = []\n",
    "    if lower == True:\n",
    "        indexes = [i for i,x in enumerate(new_lst) if  item in \" \".join(x).lower() ]\n",
    "    else:\n",
    "        indexes = [i for i,x in enumerate(new_lst) if  item in \" \".join(x)]\n",
    "    \n",
    "    result = []\n",
    "    for i in indexes:\n",
    "        for ii in range(0,len_item):\n",
    "            result.append(i+ii)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_highlighted_sentence_w_keyword(case,keyword):\n",
    "    # this function can also determine whether the case has the keyword\n",
    "    has_keyword = 0\n",
    "    \n",
    "    report = case['Report text']\n",
    "    # split report by sentence\n",
    "    report_split = report.replace('\\n','. ').split('. ')\n",
    "    report_split = [i for i in report_split if i != ' ' and i != '']\n",
    "    \n",
    "    txt = \"\"\n",
    "    highlight_sentence = []\n",
    "    keyword_list = []\n",
    "    for string in report_split:\n",
    "        # find whether the key is included in each sentence\n",
    "        keys = [key for key in keyword if key in process_string(string.lower())]\n",
    "        if len(keys) != 0:\n",
    "            has_keyword = 1\n",
    "            # save keywords\n",
    "            keyword_list.extend(keys)\n",
    "            # find the indexes of the keyword in that sentence\n",
    "            string = process_string(string)\n",
    "            string_split = string.split()\n",
    "            indexes_list = []\n",
    "            for key in keys:\n",
    "                index = indexes_for_duplicates_in_list(string_split,key)\n",
    "                indexes_list.extend(index)\n",
    "            indexes_list = sorted(indexes_list)\n",
    "            \n",
    "            # add this sentence and indexes into collection\n",
    "            highlight_sentence.append((string,indexes_list))\n",
    "            \n",
    "            # write into text\n",
    "            t = \"\"\n",
    "            for i in range(0,len(string_split)):\n",
    "                if i in indexes_list:\n",
    "                    t = t + \"!!\" + string_split[i] + \"!! \"\n",
    "                else:\n",
    "                    t = t + string_split[i]+ ' '\n",
    "            txt = txt + t +'.\\n '\n",
    "        \n",
    "    keyword_list = list(dict.fromkeys(keyword_list))\n",
    "    return has_keyword,keyword_list, highlight_sentence,txt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_highlighted_rtf_report(case,highlight_sentence,save_path,attach_full_report = True):\n",
    "    # define rtf file name\n",
    "    file_name = os.path.join(save_path,case['Patient_ID']+'.rtf')\n",
    "    txt = \"{\\\\rtf1 Patient_ID: \"+case['Patient_ID']+\"\\line\\line Highlight sentences: \\line\\line \" \n",
    "    \n",
    "    for h in highlight_sentence:\n",
    "        string = h[0]\n",
    "        indexes_list = h[1]\n",
    "        string_split = string.split()\n",
    "       \n",
    "        # write into text\n",
    "        t = \"\"\n",
    "        for i in range(0,len(string_split)):\n",
    "            if i in indexes_list:\n",
    "                t = t + \"\\\\b \" + string_split[i] + \" \\\\b0 \"\n",
    "            else:\n",
    "                t = t + string_split[i]+ ' '\n",
    "        txt = txt + t +'\\line '\n",
    "            \n",
    "    # attach the full reports\n",
    "    if attach_full_report == True:\n",
    "        report = case['Report text']\n",
    "        txt = txt + \"\\line Full reports:\\line  \" + report.replace('\\n','\\line ') + \"}\"\n",
    "    \n",
    "    output_file = open(file_name,'w')\n",
    "    output_file.write(txt)\n",
    "    output_file.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main folder\n",
    "main_folder = '/Users/zhennongchen/Documents/Zhennong_CT_Data/Patient_Overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make rtf files as well as a spreadsheet for highlight sentences\n",
    "def main(data,keyword,make_rtf_file=0,make_spreadsheet=0,include_no_keyword_cases=1,print_text=False):\n",
    "    \n",
    "    # define save path\n",
    "    os.makedirs(os.path.join(main_folder,'Case_search_list',year),exist_ok = True)\n",
    "    save_path = os.path.join(main_folder,'Case_search_list',year,'rtf_files')\n",
    "    os.makedirs(save_path,exist_ok = True)\n",
    "    spreadsheet_name = year + '_Radiology_report_w_highlight.xlsx'\n",
    "    column_list = ['Patient_ID','Keywords','Highlight text','Report text','Acession','Manufacturer','Model','Sex','Age','Protocol','Directories_Full','Directories_Function','Timeframes']\n",
    "\n",
    "    count = 0\n",
    "    data = data.fillna(0)\n",
    "    spreadsheet = []\n",
    "    for i in range(0,data.shape[0]):\n",
    "        has_keyword = 0\n",
    "        case = data.iloc[i]\n",
    "        if case['Report text'] == 0: # no report text\n",
    "            keyword_list = '';highlight_txt = ''\n",
    "        else:\n",
    "\n",
    "            has_keyword,keyword_list,highlight_sentence,highlight_txt = find_highlighted_sentence_w_keyword(case,keyword)\n",
    "\n",
    "            if has_keyword == 1:\n",
    "                count += 1\n",
    "                if make_rtf_file == 1:\n",
    "                    make_highlighted_rtf_report(case,highlight_sentence,save_path)\n",
    "            else: # no keyword\n",
    "                keyword_list = '';highlight_txt = ''\n",
    "        if include_no_keyword_cases == 1:\n",
    "            spreadsheet.append([case['Patient_ID'],keyword_list,highlight_txt,case['Report text'],case['Accession'],case['Manufacturer'],case['Model'],case['Sex'],\\\n",
    "                                case['Age'],case['Protocol'],case['Directories_Full'],\\\n",
    "                                case['Directories_Function'],case['Timeframes']])\n",
    "        else:\n",
    "            if has_keyword == 1:\n",
    "                spreadsheet.append([case['Patient_ID'],keyword_list,highlight_txt,case['Report text'],case['Accession'],case['Manufacturer'],case['Model'],case['Sex'],\\\n",
    "                                case['Age'],case['Protocol'],case['Directories_Full'],\\\n",
    "                                case['Directories_Function'],case['Timeframes']])\n",
    "            \n",
    "    if print_text == True:\n",
    "        print('finish')\n",
    "        print(count)\n",
    "\n",
    "    if make_spreadsheet == 1:\n",
    "        df = pd.DataFrame(spreadsheet,columns = column_list)\n",
    "        df.to_excel(os.path.join(os.path.dirname(save_path),spreadsheet_name),index = True)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keyword list:\n",
    "0 hypoplastic\n",
    "1 syndrome\n",
    "2 congenital\n",
    "3 chd\n",
    "4 lvad\n",
    "5 device\n",
    "6 transcatheter\n",
    "7 aortic stenosis\n",
    "8 tavr\n",
    "9 fibrillation\n",
    "10 stenosis\n",
    "11 coronary artery disease\n",
    "12 lesion\n",
    "13 ischemi\n",
    "14 failure\n",
    "15 thinning\n",
    "16 infarct\n",
    "17 hypokinesi\n",
    "18 hypokinetic\n",
    "19 akinesi\n",
    "20 akinetic\n",
    "21 dyskinesi\n",
    "22 dyskinetic\n",
    "23 hypertrophy\n",
    "24 myopathy\n",
    "25 wall motion\n",
    "26 normal\n",
    "27 function\n",
    "28 ejection fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your keywords:\n",
    "keyword = ['hypoplastic','syndrome','congenital','chd','lvad','device','transcatheter','aortic stenosis','tavr','fibrillation',\\\n",
    "           'stenosis','coronary artery disease','lesion','ischemi',\\\n",
    "           'failure','thinning','infarct','hypokinesi','hypokinetic','akinesi','akinetic','dyskinesi','dyskinetic','hypertrophy','myopathy',\\\n",
    "           'wall motion','normal','function','ejection fraction']\n",
    "#keyword = ['cteph','embolism','lead','pacing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    }
   ],
   "source": [
    "keyword = ['stenosis','lesion']\n",
    "data = pd.read_csv(os.path.join(main_folder,'Case_search_list','normal_candidates.csv')) \n",
    "count = 0\n",
    "for i in range(0,data.shape[0]):\n",
    "    case = data.iloc[i]\n",
    "    keywords_list = case['Keywords']\n",
    "    if 'aortic stenosis' in keywords_list:\n",
    "        continue\n",
    "        \n",
    "    for key in keyword:\n",
    "        if key in keywords_list:\n",
    "            count += 1\n",
    "    \n",
    "        \n",
    "print(count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in total there are 636 CT studies\n",
      "there are 357 CT studies with functional images\n",
      "finish\n",
      "98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global year\n",
    "year = '2019'\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv(os.path.join(main_folder,year+'_Patient_Radiology_Records_Full.csv'))    \n",
    "# only look for cases with funtional study\n",
    "print('in total there are %d CT studies' % (data.shape[0]))\n",
    "data = data[data['Function?'] == 'Yes']\n",
    "print('there are %d CT studies with functional images' % (data.shape[0]))\n",
    "# save rtf and excel:\n",
    "main(data,keyword,1,1)\n",
    "# stat\n",
    "#print('%s stat by keyword search:' % (year))\n",
    "#print('CHD patient: %d\\nPatient with device: %d\\nTAVR patient: %d\\nPVA patient: %d\\nPatient with stenosis mentioned: %d (aortic stenosis: %d)\\nPatient with Heart failure: %d\\nPatient with wall thinning or infarct mentioned: %d\\nPatient with WMA: %d (hypo: %d, aki: %d, dys: %d)\\nPatient with hypertrophy: %d\\nPatient with wall motion mentioned: %d' %(main(data,keyword[0:4]),\\\n",
    "    #main(data,keyword[4:6]),main(data,keyword[6:9]),\\\n",
    "     #main(data,[keyword[9]]),main(data,keyword[10:14]),main(data,[keyword[7]]),main(data,[keyword[14]]),\\\n",
    "      #main(data,keyword[15:17]),main(data,keyword[17:23]),main(data,keyword[17:19]),\\\n",
    "      #main(data,keyword[19:21]),main(data,keyword[21:23]),main(data,keyword[23:25]),main(data,[keyword[25]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in total there are 88 CT studies\n",
      "there are 60 CT studies with functional images\n",
      "finish\n",
      "58\n",
      "2017 stat by keyword search:\n",
      "CHD patient: 9\n",
      "Patient with device: 3\n",
      "TAVR patient: 19\n",
      "PVA patient: 12\n",
      "Patient with stenosis mentioned: 42 (aortic stenosis: 6)\n",
      "Patient with Heart failure: 2\n",
      "Patient with wall thinning or infarct mentioned: 3\n",
      "Patient with WMA: 4 (hypo: 1, aki: 1, dys: 3)\n",
      "Patient with hypertrophy: 9\n",
      "Patient with wall motion mentioned: 2\n"
     ]
    }
   ],
   "source": [
    "year = '2017'\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv(os.path.join(main_folder,year+'_Patient_Radiology_Records_Full.csv'))    \n",
    "# only look for cases with funtional study\n",
    "print('in total there are %d CT studies' % (data.shape[0]))\n",
    "data = data[data['Function?'] == 'Yes']\n",
    "print('there are %d CT studies with functional images' % (data.shape[0]))\n",
    "# save rtf and excel:\n",
    "main(data,keyword,1,1,True)\n",
    "# stat\n",
    "print('%s stat by keyword search:' % (year))\n",
    "print('CHD patient: %d\\nPatient with device: %d\\nTAVR patient: %d\\nPVA patient: %d\\nPatient with stenosis mentioned: %d (aortic stenosis: %d)\\nPatient with Heart failure: %d\\nPatient with wall thinning or infarct mentioned: %d\\nPatient with WMA: %d (hypo: %d, aki: %d, dys: %d)\\nPatient with hypertrophy: %d\\nPatient with wall motion mentioned: %d' %(main(data,keyword[0:4]),\\\n",
    "    main(data,keyword[4:6]),main(data,keyword[6:9]),\\\n",
    "      main(data,[keyword[9]]),main(data,keyword[10:14]),main(data,[keyword[7]]),main(data,[keyword[14]]),\\\n",
    "      main(data,keyword[15:17]),main(data,keyword[17:23]),main(data,keyword[17:19]),\\\n",
    "      main(data,keyword[19:21]),main(data,keyword[21:23]),main(data,keyword[23:25]),main(data,[keyword[25]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in total there are 796 CT studies\n",
      "there are 561 CT studies with functional images\n",
      "finish\n",
      "540\n",
      "2018 stat by keyword search:\n",
      "CHD patient: 57\n",
      "Patient with device: 84\n",
      "TAVR patient: 103\n",
      "PVA patient: 154\n",
      "Patient with stenosis mentioned: 325 (aortic stenosis: 59)\n",
      "Patient with Heart failure: 12\n",
      "Patient with wall thinning or infarct mentioned: 38\n",
      "Patient with WMA: 36 (hypo: 29, aki: 14, dys: 8)\n",
      "Patient with hypertrophy: 74\n",
      "Patient with wall motion mentioned: 18\n"
     ]
    }
   ],
   "source": [
    "global year\n",
    "year = '2018'\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv(os.path.join(main_folder,year+'_Patient_Radiology_Records_Full.csv'))    \n",
    "# only look for cases with funtional study\n",
    "print('in total there are %d CT studies' % (data.shape[0]))\n",
    "data = data[data['Function?'] == 'Yes']\n",
    "print('there are %d CT studies with functional images' % (data.shape[0]))\n",
    "# save rtf and excel:\n",
    "main(data,keyword,1,1,True)\n",
    "# stat\n",
    "print('%s stat by keyword search:' % (year))\n",
    "print('CHD patient: %d\\nPatient with device: %d\\nTAVR patient: %d\\nPVA patient: %d\\nPatient with stenosis mentioned: %d (aortic stenosis: %d)\\nPatient with Heart failure: %d\\nPatient with wall thinning or infarct mentioned: %d\\nPatient with WMA: %d (hypo: %d, aki: %d, dys: %d)\\nPatient with hypertrophy: %d\\nPatient with wall motion mentioned: %d' %(main(data,keyword[0:4]),\\\n",
    "    main(data,keyword[4:6]),main(data,keyword[6:9]),\\\n",
    "      main(data,[keyword[9]]),main(data,keyword[10:14]),main(data,[keyword[7]]),main(data,[keyword[14]]),\\\n",
    "      main(data,keyword[15:17]),main(data,keyword[17:23]),main(data,keyword[17:19]),\\\n",
    "      main(data,keyword[19:21]),main(data,keyword[21:23]),main(data,keyword[23:25]),main(data,[keyword[25]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in total there are 636 CT studies\n",
      "there are 357 CT studies with functional images\n",
      "finish\n",
      "354\n",
      "2020 stat by keyword search:\n",
      "CHD patient: 53\n",
      "Patient with device: 101\n",
      "TAVR patient: 73\n",
      "PVA patient: 56\n",
      "Patient with stenosis mentioned: 229 (aortic stenosis: 63)\n",
      "Patient with Heart failure: 15\n",
      "Patient with wall thinning or infarct mentioned: 29\n",
      "Patient with WMA: 51 (hypo: 47, aki: 14, dys: 4)\n",
      "Patient with hypertrophy: 81\n",
      "Patient with wall motion mentioned: 24\n"
     ]
    }
   ],
   "source": [
    "year = '2020'\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv(os.path.join(main_folder,year+'_Patient_Radiology_Records_Full.csv'))    \n",
    "# only look for cases with funtional study\n",
    "print('in total there are %d CT studies' % (data.shape[0]))\n",
    "data = data[data['Function?'] == 'Yes']\n",
    "print('there are %d CT studies with functional images' % (data.shape[0]))\n",
    "# save rtf and excel:\n",
    "main(data,keyword,1,1,True)\n",
    "# stat\n",
    "print('%s stat by keyword search:' % (year))\n",
    "print('CHD patient: %d\\nPatient with device: %d\\nTAVR patient: %d\\nPVA patient: %d\\nPatient with stenosis mentioned: %d (aortic stenosis: %d)\\nPatient with Heart failure: %d\\nPatient with wall thinning or infarct mentioned: %d\\nPatient with WMA: %d (hypo: %d, aki: %d, dys: %d)\\nPatient with hypertrophy: %d\\nPatient with wall motion mentioned: %d' %(main(data,keyword[0:4]),\\\n",
    "    main(data,keyword[4:6]),main(data,keyword[6:9]),\\\n",
    "      main(data,[keyword[9]]),main(data,keyword[10:14]),main(data,[keyword[7]]),main(data,[keyword[14]]),\\\n",
    "      main(data,keyword[15:17]),main(data,keyword[17:23]),main(data,keyword[17:19]),\\\n",
    "      main(data,keyword[19:21]),main(data,keyword[21:23]),main(data,keyword[23:25]),main(data,[keyword[25]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make folders in NAS for all found patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_patients = pd.read_csv(os.path.join(main_folder,'Case_search_list/normal_candidates.csv'))\n",
    "abnormal_patients = pd.read_csv(os.path.join(main_folder,'Case_search_list/abnormal_candidates.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_drive = '/Volumes/McVeighLab/wip/zhennong'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    }
   ],
   "source": [
    "print(normal_patients.shape[0])\n",
    "for i in range(0,normal_patients.shape[0]):\n",
    "    case = normal_patients.iloc[i]\n",
    "    patient_id = case['Patient_ID']\n",
    "    \n",
    "    os.makedirs(os.path.join(nas_drive,'Normal',patient_id),exist_ok = True)\n",
    "    os.makedirs(os.path.join(nas_drive,'Normal',patient_id,'img-dcm'),exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "/Volumes/McVeighLab/wip/zhennong/Normal/.DS_Store\n",
      "198\n"
     ]
    }
   ],
   "source": [
    "D = os.listdir(os.path.join(nas_drive,'Normal'))\n",
    "print(len(D))\n",
    "count = 0\n",
    "for o in D:\n",
    "    if os.path.isdir(os.path.join(nas_drive,'Normal',o)):\n",
    "        count += 1\n",
    "    else:\n",
    "        print(os.path.join(nas_drive,'Normal',o))\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check whether the transfer is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVC1803021059\n",
      "CVC1806211500\n",
      "CVC1901041049\n",
      "CVC1902011416\n",
      "CVC1905281114\n",
      "CVC1910071424\n",
      "CVC2003041013\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,normal_patients.shape[0]):\n",
    "    case = normal_patients.iloc[i]\n",
    "    patient_id = case['Patient_ID']\n",
    "    \n",
    "    folder1 = os.path.join(nas_drive,'Normal',patient_id)\n",
    "    if os.path.isdir(folder1) != 1:\n",
    "        print(patient_id)\n",
    "    \n",
    "    D = os.listdir(os.path.join(folder1,'img-dcm'))\n",
    "    if len(D) < 9:\n",
    "        print(patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVC1802141345\n",
      "CVC1803121651\n",
      "CVC1804301009\n",
      "CVC1805221523\n",
      "CVC1801040932\n",
      "CVC1901281242\n",
      "CVC1902211408\n",
      "CVC1903211114\n",
      "CVC1904151124\n",
      "CVC1905211108\n",
      "CVC1906151814\n",
      "CVC1908220904\n",
      "CVC1908300959\n",
      "CVC1911021733\n",
      "CVC1901141121\n",
      "CVC1902191419\n",
      "CVC1904221514\n",
      "CVC1910091025\n",
      "CVC2003251150\n",
      "CVC2004071136\n",
      "CVC2004071506\n",
      "CVC2004161410\n",
      "CVC2006181459\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,abnormal_patients.shape[0]):\n",
    "    case = abnormal_patients.iloc[i]\n",
    "    patient_id = case['Patient_ID']\n",
    "    \n",
    "    folder1 = os.path.join(nas_drive,'Abnormal',patient_id)\n",
    "    if os.path.isdir(folder1) != 1:\n",
    "        print(patient_id)\n",
    "    \n",
    "    D = os.listdir(os.path.join(folder1,'img-dcm'))\n",
    "    if len(D) < 9:\n",
    "        print(patient_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
